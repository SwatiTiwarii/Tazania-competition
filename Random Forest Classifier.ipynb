{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://github.com/zlatankr/Projects/tree/master/Tanzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import feature_process_helper\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 39)\n",
      "(5083, 39)\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd()+'/data/'\n",
    "\n",
    "train_data = pd.read_csv(f'{data_dir}train.csv' , index_col = 'new_ids') ##\n",
    "test_data = pd.read_csv(f'{data_dir}test.csv' , index_col = 'new_ids') ## \n",
    "\n",
    "\n",
    "\n",
    "X_train = train_data.copy()\n",
    "X_test = test_data.copy()\n",
    "y_train = X_train[['defective']]\n",
    "X_train.drop(columns=['defective'] , inplace=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/jitesh.arora/anaconda3/envs/fastainew/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train['defective'] = y_train['defective'].apply(lambda x: 1 if x=='yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates(X_train, X_test):\n",
    "    \"\"\"\n",
    "    date_recorded: this might be a useful variable for this analysis, although the year itself would be useless in a practical scenario moving into the future. We will convert this column into a datetime, and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed for now. We will delete date_recorded itself, since random forest cannot accept datetime\n",
    "    \"\"\"\n",
    "    for i in [X_train, X_test]:\n",
    "        i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
    "        i['year_recorded'] = i['date_recorded'].apply(lambda x: x.year)\n",
    "        i['month_recorded'] = i['date_recorded'].apply(lambda x: x.month)\n",
    "        i['date_recorded'] = (pd.to_datetime(i['date_recorded'])).apply(lambda x: x.toordinal())\n",
    "    return X_train, X_test\n",
    "\n",
    "def dates2(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Turn year_recorded and month_recorded into dummy variables\n",
    "    \"\"\"\n",
    "    for z in ['month_recorded', 'year_recorded']:\n",
    "        X_train[z] = X_train[z].apply(lambda x: str(x))\n",
    "        X_test[z] = X_test[z].apply(lambda x: str(x))\n",
    "        good_cols = [z+'_'+i for i in X_train[z].unique() if i in X_test[z].unique()]\n",
    "        X_train = pd.concat((X_train, pd.get_dummies(X_train[z], prefix = z)[good_cols]), axis = 1)\n",
    "        X_test = pd.concat((X_test, pd.get_dummies(X_test[z], prefix = z)[good_cols]), axis = 1)\n",
    "        del X_test[z]\n",
    "        del X_train[z]\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "def construction(X_train, X_test):\n",
    "    for i in [X_train, X_test]:\n",
    "        i['construction_year'].replace(0, X_train[X_train['construction_year'] != 0]['construction_year'].median(), inplace=True)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def bools(X_train, X_test):\n",
    "    \"\"\"\n",
    "    public_meeting: we will fill the nulls as 'False'\n",
    "    permit: we will fill the nulls as 'False\n",
    "    \"\"\"\n",
    "    z = ['public_meeting', 'permit']\n",
    "    for i in z:\n",
    "        X_train[i].fillna(False, inplace = True)\n",
    "        X_train[i] = X_train[i].apply(lambda x: float(x))\n",
    "        X_test[i].fillna(False, inplace = True)\n",
    "        X_test[i] = X_test[i].apply(lambda x: float(x))\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def locs(X_train, X_test):\n",
    "    \"\"\"\n",
    "    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using means from \n",
    "    ['subvillage', 'district_code', 'basin'], and lastly the overall mean\n",
    "    \"\"\"\n",
    "    trans = ['longitude', 'latitude', 'gps_height', 'population']\n",
    "    for i in [X_train, X_test]:\n",
    "        i.loc[i.longitude == 0, 'latitude'] = 0\n",
    "    for z in trans:\n",
    "        for i in [X_train, X_test]:\n",
    "            i[z].replace(0., np.NaN, inplace = True)\n",
    "            i[z].replace(1., np.NaN, inplace = True)\n",
    "        \n",
    "        for j in ['subvillage', 'district_code', 'basin']:\n",
    "        \n",
    "            X_train['mean'] = X_train.groupby([j])[z].transform('mean')\n",
    "            X_train[z] = X_train[z].fillna(X_train['mean'])\n",
    "            o = X_train.groupby([j])[z].mean()\n",
    "            fill = pd.merge(X_test, pd.DataFrame(o), left_on=[j], right_index=True, how='left').iloc[:,-1]\n",
    "            X_test[z] = X_test[z].fillna(fill)\n",
    "        \n",
    "        X_train[z] = X_train[z].fillna(X_train[z].mean())\n",
    "        X_test[z] = X_test[z].fillna(X_train[z].mean())\n",
    "        del X_train['mean']\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def removal2(X_train, X_test):\n",
    "    z = ['amount_tsh',  'num_private', 'region', \n",
    "          'quantity', 'quality_group', 'source_type', 'payment', \n",
    "          'waterpoint_type_group',\n",
    "         'extraction_type_group' , 'scheme_name']\n",
    "    for i in z:\n",
    "        del X_train[i]\n",
    "        del X_test[i]\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "def small_n2(X_train, X_test):\n",
    "    cols = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "    #print(cols)\n",
    "    X_train[cols] = X_train[cols].where(X_train[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
    "    for column in cols:\n",
    "        for i in X_test[column].unique():\n",
    "            if i not in X_train[column].unique():\n",
    "                X_test[column].replace(i, 'other', inplace=True)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dummies(X_train, X_test):\n",
    "    columns = [i for i in X_train.columns if type(X_train[i].iloc[0]) == str]\n",
    "    for column in columns:\n",
    "        X_train[column].fillna('NULL', inplace = True)\n",
    "        good_cols = [column+'_'+i for i in X_train[column].unique() if i in X_test[column].unique()]\n",
    "        X_train = pd.concat((X_train, pd.get_dummies(X_train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        X_test = pd.concat((X_test, pd.get_dummies(X_test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del X_train[column]\n",
    "        del X_test[column]\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def lda(X_train, X_test, y_train, cols=['population', 'gps_height', 'latitude', 'longitude']):\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = sc.fit_transform(X_train[cols])\n",
    "    X_test_std = sc.transform(X_test[cols])\n",
    "    lda = LDA(n_components=None)\n",
    "    X_train_lda = lda.fit_transform(X_train_std, y_train.values.ravel())\n",
    "    X_test_lda = lda.transform(X_test_std)\n",
    "    \n",
    "    X_train_lda = pd.DataFrame(X_train_lda , index = X_train.index)\n",
    "    X_test_lda = pd.DataFrame(X_test_lda , index = X_test.index)\n",
    "    \n",
    "    X_train = pd.merge(X_train_lda , X_train , left_index=True , right_index = True)\n",
    "    X_test  = pd.merge(X_test_lda , X_test , left_index=True , right_index=True)\n",
    "    \n",
    "    #X_train = pd.concat((pd.DataFrame(X_train_lda), X_train), axis=1)\n",
    "    #X_test = pd.concat((pd.DataFrame(X_test_lda), X_test), axis=1)\n",
    "    for i in cols:\n",
    "        del X_train[i]\n",
    "        del X_test[i]\n",
    "    return X_train, X_test\n",
    "\n",
    "def gini(p):\n",
    "    return 1-(p**2 + (1-p)**2)\n",
    "\n",
    "def impurity(X_train):\n",
    "    imp = {}\n",
    "    for i in X_train.columns[17:]:\n",
    "        imp[i] = gini(X_train[i].mean())\n",
    "    return imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created ordinal data feature and few month, yearly features. Missing value imputation have been taken care separately for separate features. \n",
    "For location features such as latitude , longitude , gps height and population , use mean value of sub village, district code and basin and finally the overall mean. \n",
    "For boolean features : public meeting and permit, fill null values with False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = dates(X_train, X_test)\n",
    "X_train, X_test = dates2(X_train, X_test)\n",
    "\n",
    "X_train, X_test = construction(X_train, X_test)\n",
    "X_train, X_test = bools(X_train, X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = locs(X_train, X_test)\n",
    "X_train['population'] = np.log(X_train['population'])\n",
    "X_test['population'] = np.log(X_test['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are removing features which are mostly empty or constant- amount_tsh , num_private , scheme_name. Also for highly correlated features we are keeping only 1 feature ( refer EDA analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for some of the categorical features ,we are clubbing very infrequent catergories( with count less than 100) into  a single catergory. This will be helpful to control size of one hot encode vectors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = removal2(X_train, X_test)\n",
    "X_train, X_test = small_n2(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns we are converting the features into LDA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 45)\n",
      "(5083, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 442)\n",
      "(5083, 442)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = lda(X_train, X_test, y_train)\n",
    "X_train, X_test = dummies(X_train, X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 442)\n",
      "(12500, 442)\n",
      "(37500, 1)\n",
      "(12500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_val.shape)\n",
    "print(y_tr.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>month_recorded_2</th>\n",
       "      <th>month_recorded_1</th>\n",
       "      <th>month_recorded_3</th>\n",
       "      <th>...</th>\n",
       "      <th>source_other</th>\n",
       "      <th>source_class_groundwater</th>\n",
       "      <th>source_class_surface</th>\n",
       "      <th>source_class_unknown</th>\n",
       "      <th>waterpoint_type_hand pump</th>\n",
       "      <th>waterpoint_type_communal standpipe</th>\n",
       "      <th>waterpoint_type_other</th>\n",
       "      <th>waterpoint_type_communal standpipe multiple</th>\n",
       "      <th>waterpoint_type_improved spring</th>\n",
       "      <th>waterpoint_type_cattle trough</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43793</th>\n",
       "      <td>-0.087682</td>\n",
       "      <td>734351</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52729</th>\n",
       "      <td>-1.477396</td>\n",
       "      <td>734335</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0  date_recorded  region_code  district_code  public_meeting  \\\n",
       "new_ids                                                                        \n",
       "43793   -0.087682         734351           12              4             1.0   \n",
       "52729   -1.477396         734335           15              2             1.0   \n",
       "\n",
       "         permit  construction_year  month_recorded_2  month_recorded_1  \\\n",
       "new_ids                                                                  \n",
       "43793       0.0               2000                 0                 0   \n",
       "52729       0.0               1991                 0                 0   \n",
       "\n",
       "         month_recorded_3              ...                source_other  \\\n",
       "new_ids                                ...                               \n",
       "43793                   0              ...                           0   \n",
       "52729                   0              ...                           0   \n",
       "\n",
       "         source_class_groundwater  source_class_surface  source_class_unknown  \\\n",
       "new_ids                                                                         \n",
       "43793                           1                     0                     0   \n",
       "52729                           1                     0                     0   \n",
       "\n",
       "         waterpoint_type_hand pump  waterpoint_type_communal standpipe  \\\n",
       "new_ids                                                                  \n",
       "43793                            0                                   1   \n",
       "52729                            1                                   0   \n",
       "\n",
       "         waterpoint_type_other  waterpoint_type_communal standpipe multiple  \\\n",
       "new_ids                                                                       \n",
       "43793                        0                                            0   \n",
       "52729                        0                                            0   \n",
       "\n",
       "         waterpoint_type_improved spring  waterpoint_type_cattle trough  \n",
       "new_ids                                                                  \n",
       "43793                                  0                              0  \n",
       "52729                                  0                              0  \n",
       "\n",
       "[2 rows x 442 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom metric for data challenge is as follows: false negative rate is weighted 90% more that false positive rate for calcuating error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y , ypred):\n",
    "    #set_trace()\n",
    "    \n",
    "    misses = 1- (ypred ==y)\n",
    "    false_pos = misses*(1-y)\n",
    "    false_neg = misses *y\n",
    "    false_pos_rate = false_pos.sum()/ (len(y) - int(y.sum()))\n",
    "    false_neg_rate = false_neg.sum()/ (int(y.sum()))\n",
    "    \n",
    "    score = 1 - ( 0.9 * false_neg_rate  +  0.1 * false_pos_rate) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/jitesh.arora/anaconda3/envs/fastainew/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/FRACTAL/jitesh.arora/anaconda3/envs/fastainew/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/FRACTAL/jitesh.arora/anaconda3/envs/fastainew/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:   35.5s\n",
      "/home/FRACTAL/jitesh.arora/anaconda3/envs/fastainew/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=3)]: Done  80 out of  80 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "             \"criterion\": [ \"entropy\" ],  \n",
    "             'n_jobs' : [3],\n",
    "             'bootstrap': [True , False], \n",
    "             'max_depth': [20, 40],  \n",
    "             'max_features': ['auto'],\n",
    "             'min_samples_leaf': [ 2, 4],\n",
    "             'min_samples_split': [ 2 ,6],\n",
    "             'n_estimators': [  200]  ,\n",
    "            'class_weight' : ['balanced']\n",
    "             }\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "cv_5 = KFold(n_splits=5)\n",
    "\n",
    "gs = GridSearchCV(RandomForestClassifier(random_state = 12),param_grid=param_grid,\n",
    "                scoring  = make_scorer(custom_accuracy),cv= cv_5,  n_jobs=3 , verbose = 5 , refit= True)  #n_iter = 100,\n",
    "\n",
    "gs = gs.fit(X_tr, y_tr.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_tr , y_tr.values.ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom accuracy in validation set 0.8043335824159802\n"
     ]
    }
   ],
   "source": [
    "val_pred = clf.predict(X_val)\n",
    "print('Custom accuracy in validation set' , custom_accuracy(y_val.values.ravel() , val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv_5 = StratifiedKFold(n_splits=5)\n",
    "\n",
    "full_train= X_train.copy()\n",
    "full_labels = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing custom accuracy across different grid search cross validation data sets. All of them are around 80-81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom accuracy  0.8085153387273979\n",
      "custom accuracy  0.8121529442425978\n",
      "custom accuracy  0.809849756736739\n",
      "custom accuracy  0.8023772326602174\n",
      "custom accuracy  0.8061448153562172\n"
     ]
    }
   ],
   "source": [
    "for train_ind, test_ind in cv_5.split(full_train, full_labels):\n",
    "\n",
    "    feat_train, feat_test = full_train.iloc[train_ind], full_train.iloc[test_ind]\n",
    "    label_train, label_test = full_labels.iloc[train_ind],full_labels.iloc[test_ind]\n",
    "    clf.fit(feat_train,label_train.values.ravel())\n",
    "    predictions = gs.best_estimator_.predict_proba(feat_test)\n",
    "    preds = np.where(predictions[:, 1]>=0.5, 1, 0) \n",
    "    print('custom accuracy ' , custom_accuracy(label_test['defective'] , preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(clf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>quantity_group_dry</td>\n",
       "      <td>0.110352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.062053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>construction_year</td>\n",
       "      <td>0.048599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date_recorded</td>\n",
       "      <td>0.044175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>quantity_group_enough</td>\n",
       "      <td>0.038828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>waterpoint_type_other</td>\n",
       "      <td>0.033844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>extraction_type_class_other</td>\n",
       "      <td>0.029707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>extraction_type_other</td>\n",
       "      <td>0.026450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>region_code</td>\n",
       "      <td>0.020152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>district_code</td>\n",
       "      <td>0.019111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>payment_type_never pay</td>\n",
       "      <td>0.018128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>quantity_group_insufficient</td>\n",
       "      <td>0.014672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>waterpoint_type_communal standpipe</td>\n",
       "      <td>0.011951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>extraction_type_class_handpump</td>\n",
       "      <td>0.009988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>funder_Government Of Tanzania</td>\n",
       "      <td>0.009974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>water_quality_unknown</td>\n",
       "      <td>0.009690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>payment_type_per bucket</td>\n",
       "      <td>0.008634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>waterpoint_type_communal standpipe multiple</td>\n",
       "      <td>0.008569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>management_vwc</td>\n",
       "      <td>0.008157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>waterpoint_type_hand pump</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable  importance\n",
       "423                           quantity_group_dry    0.110352\n",
       "0                                              0    0.062053\n",
       "6                              construction_year    0.048599\n",
       "1                                  date_recorded    0.044175\n",
       "419                        quantity_group_enough    0.038828\n",
       "438                        waterpoint_type_other    0.033844\n",
       "386                  extraction_type_class_other    0.029707\n",
       "378                        extraction_type_other    0.026450\n",
       "2                                    region_code    0.020152\n",
       "3                                  district_code    0.019111\n",
       "407                       payment_type_never pay    0.018128\n",
       "421                  quantity_group_insufficient    0.014672\n",
       "437           waterpoint_type_communal standpipe    0.011951\n",
       "382               extraction_type_class_handpump    0.009988\n",
       "23                 funder_Government Of Tanzania    0.009974\n",
       "414                        water_quality_unknown    0.009690\n",
       "408                      payment_type_per bucket    0.008634\n",
       "439  waterpoint_type_communal standpipe multiple    0.008569\n",
       "389                               management_vwc    0.008157\n",
       "436                    waterpoint_type_hand pump    0.008002"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quality_group_dry is coming top most important feature in determining the functional condition of hand pumps. LDA variable with information about population , latitude and longitude is coming next most important. \n",
    "\n",
    "We need to look at some algorithms such as LightGBM and CatBoost to take care of categorical features in better ways.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
